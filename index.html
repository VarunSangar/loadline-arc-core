import asyncio

# ==============================
# HARDWARE INTERFACE
# ==============================
from hardware_interface.eeg_device import EEGDevice

# ==============================
# CORE SYSTEM MODULES
# ==============================
from cognition.state import CognitiveState
from vision.context import VisionContext
from reasoning.subject import SubjectClassifier
from reasoning.math import MathSolver
from reasoning.mcq import MCQReasoner
from output.voice import VoiceOutput
from integration.loadline_api import LoadlineAPI


# ==================================================
# LOADLINE ARC — MAIN ORCHESTRATOR
# ==================================================

class LoadlineARC:
    def __init__(self):
        # EEG source (real or simulated decided internally)
        self.eeg = EEGDevice()

        # Cognitive modeling
        self.cognition = CognitiveState()

        # Context + reasoning
        self.vision = VisionContext()
        self.subjects = SubjectClassifier()
        self.math = MathSolver()
        self.mcq = MCQReasoner()

        # Output
        self.voice = VoiceOutput()

        # Loadline integration (existing platform)
        self.loadline = LoadlineAPI(
            endpoint="https://varunsangar.github.io/LOADLINE/"
        )

        print("[ARC] Initialized successfully")

    async def run(self):
        while True:
            # ==============================
            # EEG → COGNITIVE STATE
            # ==============================
            eeg = self.eeg.read()
            state = self.cognition.analyze(eeg)

            print("[COGNITIVE STATE]", state)

            # Voice intervention if overloaded
            if state["state"] == "overloaded":
                self.voice.speak(
                    "Cognitive load is high. Slow your breathing and refocus."
                )

            # ==============================
            # CAMERA → CONTEXT
            # ==============================
            text = self.vision.capture_text()

            if not text or not text.strip():
                await asyncio.sleep(2)
                continue

            subject = self.subjects.classify(text)
            print("[SUBJECT]", subject)

            # ==============================
            # SEND DATA TO LOADLINE
            # ==============================
            try:
                self.loadline.send_cli(
                    cli=state.get("cli", state.get("load")),
                    subject=subject
                )
            except Exception as e:
                print("[LOADLINE WARNING]", e)

            # ==============================
            # DECISION LOGIC
            # ==============================
            if subject == "math":
                response = self.math.solve(text)
                print("[MATH RESPONSE]", response)
                self.voice.speak(response)

            elif subject != "unknown":
                guidance = self.mcq.analyze(text)
                print("[GUIDANCE]", guidance)
                self.voice.speak(
                    "This is not math. I can guide you through the reasoning."
                )

            await asyncio.sleep(2)


# ==============================
# ENTRY POINT
# ==============================

if __name__ == "__main__":
    arc = LoadlineARC()
    asyncio.run(arc.run())
